{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a62ec204-799b-4324-b58f-a48c1fc171cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2207359188060061>:12\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdelta\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
       "\u001B[1;32m      3\u001B[0m DeltaTable\u001B[38;5;241m.\u001B[39mcreate(spark) \\\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;241m.\u001B[39mtableName(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124memployee_demo\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;241m.\u001B[39maddColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124memp_id\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mINT\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n",
       "\u001B[1;32m      6\u001B[0m \u001B[38;5;241m.\u001B[39maddColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124memp_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSTRING\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;241m.\u001B[39maddColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgender\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSTRING\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;241m.\u001B[39maddColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msalary\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mINT\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n",
       "\u001B[1;32m      9\u001B[0m \u001B[38;5;241m.\u001B[39maddColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDept\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSTRING\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n",
       "\u001B[1;32m     10\u001B[0m \u001B[38;5;241m.\u001B[39mproperty(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtable created for demo purpose\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n",
       "\u001B[1;32m     11\u001B[0m \u001B[38;5;241m.\u001B[39mlocation(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdbfs:/FileStore/tables/delta2\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n",
       "\u001B[0;32m---> 12\u001B[0m \u001B[38;5;241m.\u001B[39mexecute()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/delta/tables.py:1467\u001B[0m, in \u001B[0;36mDeltaTableBuilder.execute\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m   1458\u001B[0m \u001B[38;5;129m@since\u001B[39m(\u001B[38;5;241m1.0\u001B[39m)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
       "\u001B[1;32m   1459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexecute\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DeltaTable:\n",
       "\u001B[1;32m   1460\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m   1461\u001B[0m \u001B[38;5;124;03m    Execute Table Creation.\u001B[39;00m\n",
       "\u001B[1;32m   1462\u001B[0m \n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   1465\u001B[0m \u001B[38;5;124;03m    .. note:: Evolving\u001B[39;00m\n",
       "\u001B[1;32m   1466\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 1467\u001B[0m     jdt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1468\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DeltaTable(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_spark, jdt)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:168\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    164\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    166\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    167\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 168\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    170\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_ALREADY_EXISTS] Cannot create table or view `default`.`employee_demo` because it already exists.\n",
       "Choose a different name, drop or replace the existing object, add the IF NOT EXISTS clause to tolerate pre-existing objects, or add the OR REFRESH clause to refresh the existing streaming table."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-2207359188060061>:12\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdelta\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m      3\u001B[0m DeltaTable\u001B[38;5;241m.\u001B[39mcreate(spark) \\\n\u001B[1;32m      4\u001B[0m \u001B[38;5;241m.\u001B[39mtableName(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124memployee_demo\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[1;32m      5\u001B[0m \u001B[38;5;241m.\u001B[39maddColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124memp_id\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mINT\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[1;32m      6\u001B[0m \u001B[38;5;241m.\u001B[39maddColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124memp_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSTRING\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[1;32m      7\u001B[0m \u001B[38;5;241m.\u001B[39maddColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgender\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSTRING\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[1;32m      8\u001B[0m \u001B[38;5;241m.\u001B[39maddColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msalary\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mINT\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[1;32m      9\u001B[0m \u001B[38;5;241m.\u001B[39maddColumn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDept\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSTRING\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[1;32m     10\u001B[0m \u001B[38;5;241m.\u001B[39mproperty(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtable created for demo purpose\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[1;32m     11\u001B[0m \u001B[38;5;241m.\u001B[39mlocation(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdbfs:/FileStore/tables/delta2\u001B[39m\u001B[38;5;124m'\u001B[39m)\\\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;241m.\u001B[39mexecute()\n\nFile \u001B[0;32m/databricks/spark/python/delta/tables.py:1467\u001B[0m, in \u001B[0;36mDeltaTableBuilder.execute\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1458\u001B[0m \u001B[38;5;129m@since\u001B[39m(\u001B[38;5;241m1.0\u001B[39m)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m   1459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexecute\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DeltaTable:\n\u001B[1;32m   1460\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1461\u001B[0m \u001B[38;5;124;03m    Execute Table Creation.\u001B[39;00m\n\u001B[1;32m   1462\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1465\u001B[0m \u001B[38;5;124;03m    .. note:: Evolving\u001B[39;00m\n\u001B[1;32m   1466\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1467\u001B[0m     jdt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1468\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DeltaTable(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_spark, jdt)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:168\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    164\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 168\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    170\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: [TABLE_OR_VIEW_ALREADY_EXISTS] Cannot create table or view `default`.`employee_demo` because it already exists.\nChoose a different name, drop or replace the existing object, add the IF NOT EXISTS clause to tolerate pre-existing objects, or add the OR REFRESH clause to refresh the existing streaming table.",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [TABLE_OR_VIEW_ALREADY_EXISTS] Cannot create table or view `default`.`employee_demo` because it already exists.\nChoose a different name, drop or replace the existing object, add the IF NOT EXISTS clause to tolerate pre-existing objects, or add the OR REFRESH clause to refresh the existing streaming table.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from delta.tables import *\n",
    "\n",
    "DeltaTable.create(spark) \\\n",
    ".tableName('employee_demo')\\\n",
    ".addColumn('emp_id', 'INT')\\\n",
    ".addColumn('emp_name', 'STRING')\\\n",
    ".addColumn('gender', 'STRING')\\\n",
    ".addColumn('salary', 'INT')\\\n",
    ".addColumn('Dept', 'STRING')\\\n",
    ".property('description','table created for demo purpose')\\\n",
    ".location('dbfs:/FileStore/tables/delta2')\\\n",
    ".execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9790b3d-bd8c-4525-a9b5-306097e4a743",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody><tr><td>1</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         1
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_inserted_rows",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 9
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "insert into employee_demo values (100, 'Stephen','M',2000,'IT');\n",
    "insert into employee_demo values (200, 'Philipp','M',2000,'HR');\n",
    "insert into employee_demo values (300, 'Lara','F',2000,'SALES');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba6fdc98-0c45-4670-a2b6-6ea712c1e6ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>emp_id</th><th>emp_name</th><th>gender</th><th>salary</th><th>Dept</th></tr></thead><tbody><tr><td>100</td><td>Stephen</td><td>M</td><td>2000</td><td>IT</td></tr><tr><td>200</td><td>Philipp</td><td>M</td><td>2000</td><td>HR</td></tr><tr><td>300</td><td>Lara</td><td>F</td><td>2000</td><td>SALES</td></tr><tr><td>100</td><td>Stephen</td><td>M</td><td>2000</td><td>IT</td></tr><tr><td>200</td><td>Philipp</td><td>M</td><td>2000</td><td>HR</td></tr><tr><td>300</td><td>Lara</td><td>F</td><td>2000</td><td>SALES</td></tr><tr><td>100</td><td>Stephen</td><td>M</td><td>2000</td><td>IT</td></tr><tr><td>200</td><td>Philipp</td><td>M</td><td>2000</td><td>HR</td></tr><tr><td>300</td><td>Lara</td><td>F</td><td>2000</td><td>SALES</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         100,
         "Stephen",
         "M",
         2000,
         "IT"
        ],
        [
         200,
         "Philipp",
         "M",
         2000,
         "HR"
        ],
        [
         300,
         "Lara",
         "F",
         2000,
         "SALES"
        ],
        [
         100,
         "Stephen",
         "M",
         2000,
         "IT"
        ],
        [
         200,
         "Philipp",
         "M",
         2000,
         "HR"
        ],
        [
         300,
         "Lara",
         "F",
         2000,
         "SALES"
        ],
        [
         100,
         "Stephen",
         "M",
         2000,
         "IT"
        ],
        [
         200,
         "Philipp",
         "M",
         2000,
         "HR"
        ],
        [
         300,
         "Lara",
         "F",
         2000,
         "SALES"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "emp_id",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "emp_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "gender",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "salary",
            "nullable": true,
            "type": "integer"
           },
           {
            "metadata": {},
            "name": "Dept",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 11
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "emp_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "emp_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Dept",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from employee_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b7c7205-14cd-4070-aa0c-33fd19186a48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2692002494841703>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m deltaInstance1 \u001B[38;5;241m=\u001B[39m \u001B[43mDeltaTable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspark\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdbfs:/FileStore/tables/delta2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/delta/tables.py:402\u001B[0m, in \u001B[0;36mDeltaTable.forPath\u001B[0;34m(cls, sparkSession, path, hadoopConf)\u001B[0m\n",
       "\u001B[1;32m    399\u001B[0m jvm: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJVMView\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m sparkSession\u001B[38;5;241m.\u001B[39m_sc\u001B[38;5;241m.\u001B[39m_jvm  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n",
       "\u001B[1;32m    400\u001B[0m jsparkSession: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJavaObject\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m sparkSession\u001B[38;5;241m.\u001B[39m_jsparkSession  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n",
       "\u001B[0;32m--> 402\u001B[0m jdt \u001B[38;5;241m=\u001B[39m \u001B[43mjvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdelta\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtables\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDeltaTable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjsparkSession\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhadoopConf\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    403\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DeltaTable(sparkSession, jdt)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:168\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    164\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    166\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    167\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 168\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    170\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: `dbfs:/FileStore/tables/delta2` is not a Delta table."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-2692002494841703>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m deltaInstance1 \u001B[38;5;241m=\u001B[39m \u001B[43mDeltaTable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspark\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdbfs:/FileStore/tables/delta2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/delta/tables.py:402\u001B[0m, in \u001B[0;36mDeltaTable.forPath\u001B[0;34m(cls, sparkSession, path, hadoopConf)\u001B[0m\n\u001B[1;32m    399\u001B[0m jvm: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJVMView\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m sparkSession\u001B[38;5;241m.\u001B[39m_sc\u001B[38;5;241m.\u001B[39m_jvm  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m    400\u001B[0m jsparkSession: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJavaObject\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m sparkSession\u001B[38;5;241m.\u001B[39m_jsparkSession  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m--> 402\u001B[0m jdt \u001B[38;5;241m=\u001B[39m \u001B[43mjvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdelta\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtables\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDeltaTable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjsparkSession\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhadoopConf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    403\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DeltaTable(sparkSession, jdt)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:168\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    164\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 168\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    170\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: `dbfs:/FileStore/tables/delta2` is not a Delta table.",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: `dbfs:/FileStore/tables/delta2` is not a Delta table.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "deltaInstance1 = DeltaTable.forPath(spark, \"dbfs:/FileStore/tables/delta2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63650393-3efb-43f0-a131-37472da802e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2692002494841704>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m display(\u001B[43mdeltaInstance1\u001B[49m\u001B[38;5;241m.\u001B[39mtoDF())\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'deltaInstance1' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-2692002494841704>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m display(\u001B[43mdeltaInstance1\u001B[49m\u001B[38;5;241m.\u001B[39mtoDF())\n\n\u001B[0;31mNameError\u001B[0m: name 'deltaInstance1' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'deltaInstance1' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(deltaInstance1.toDF())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b1b73cb-d185-4fd4-abf4-8af09af654c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "delete from employee_demo where emp_id=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68950c6f-9865-4d7f-a402-81938f857e81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "deltaInstance1.delete('emp_id=200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "486c588b-f6c0-4f0d-b61b-fecac670509b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(deltaInstance1.toDF())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25f1632d-f0f1-4186-bbbc-f282f4c284e7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###Second Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dc19368-805d-46e9-8f5f-0d2fe2267689",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "deltaInstance2 = DeltaTable.forName(spark, 'employee_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ebb9c1f-405a-437c-a6c9-f21b10ab1370",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>emp_id</th><th>emp_name</th><th>gender</th><th>salary</th><th>Dept</th></tr></thead><tbody><tr><td>100</td><td>Stephen</td><td>M</td><td>2000</td><td>IT</td></tr><tr><td>200</td><td>Philipp</td><td>M</td><td>2000</td><td>HR</td></tr><tr><td>300</td><td>Lara</td><td>F</td><td>2000</td><td>SALES</td></tr><tr><td>100</td><td>Stephen</td><td>M</td><td>2000</td><td>IT</td></tr><tr><td>200</td><td>Philipp</td><td>M</td><td>2000</td><td>HR</td></tr><tr><td>300</td><td>Lara</td><td>F</td><td>2000</td><td>SALES</td></tr><tr><td>100</td><td>Stephen</td><td>M</td><td>2000</td><td>IT</td></tr><tr><td>200</td><td>Philipp</td><td>M</td><td>2000</td><td>HR</td></tr><tr><td>300</td><td>Lara</td><td>F</td><td>2000</td><td>SALES</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         100,
         "Stephen",
         "M",
         2000,
         "IT"
        ],
        [
         200,
         "Philipp",
         "M",
         2000,
         "HR"
        ],
        [
         300,
         "Lara",
         "F",
         2000,
         "SALES"
        ],
        [
         100,
         "Stephen",
         "M",
         2000,
         "IT"
        ],
        [
         200,
         "Philipp",
         "M",
         2000,
         "HR"
        ],
        [
         300,
         "Lara",
         "F",
         2000,
         "SALES"
        ],
        [
         100,
         "Stephen",
         "M",
         2000,
         "IT"
        ],
        [
         200,
         "Philipp",
         "M",
         2000,
         "HR"
        ],
        [
         300,
         "Lara",
         "F",
         2000,
         "SALES"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "emp_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "emp_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Dept",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(deltaInstance2.toDF())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab98c487-f1ee-4dea-b4a3-46b2dae96f9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>9</td><td>2023-06-20T17:01:12.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>8</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>8</td><td>2023-06-20T17:01:10.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>7</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>7</td><td>2023-06-20T17:01:08.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>6</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>6</td><td>2023-06-20T17:00:42.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>5</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>5</td><td>2023-06-20T17:00:40.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>4</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>4</td><td>2023-06-20T17:00:37.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>3</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>3</td><td>2023-06-20T16:55:42.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>2</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>2</td><td>2023-06-20T16:55:40.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>1</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>1</td><td>2023-06-20T16:55:36.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>0</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>0</td><td>2023-06-19T18:32:33.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>CREATE TABLE</td><td>Map(isManaged -> false, description -> null, partitionBy -> [], properties -> {\"description\":\"table created for demo purpose\"})</td><td>null</td><td>List(3644201334229790)</td><td>0619-182143-stpqxci1</td><td>null</td><td>WriteSerializable</td><td>true</td><td>Map()</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         9,
         "2023-06-20T17:01:12.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         8,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         8,
         "2023-06-20T17:01:10.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         7,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         7,
         "2023-06-20T17:01:08.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         6,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         6,
         "2023-06-20T17:00:42.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         5,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         5,
         "2023-06-20T17:00:40.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         4,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         4,
         "2023-06-20T17:00:37.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         3,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         3,
         "2023-06-20T16:55:42.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         2,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         2,
         "2023-06-20T16:55:40.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         1,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         1,
         "2023-06-20T16:55:36.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         0,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         0,
         "2023-06-19T18:32:33.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "CREATE TABLE",
         {
          "description": null,
          "isManaged": "false",
          "partitionBy": "[]",
          "properties": "{\"description\":\"table created for demo purpose\"}"
         },
         null,
         [
          "3644201334229790"
         ],
         "0619-182143-stpqxci1",
         null,
         "WriteSerializable",
         true,
         {},
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "version",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "timestamp",
            "nullable": true,
            "type": "timestamp"
           },
           {
            "metadata": {},
            "name": "userId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "userName",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operation",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "operationParameters",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "job",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "jobId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobName",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "runId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "jobOwnerId",
               "nullable": true,
               "type": "string"
              },
              {
               "metadata": {},
               "name": "triggerType",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "notebook",
            "nullable": true,
            "type": {
             "fields": [
              {
               "metadata": {},
               "name": "notebookId",
               "nullable": true,
               "type": "string"
              }
             ],
             "type": "struct"
            }
           },
           {
            "metadata": {},
            "name": "clusterId",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "readVersion",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "isolationLevel",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "isBlindAppend",
            "nullable": true,
            "type": "boolean"
           },
           {
            "metadata": {},
            "name": "operationMetrics",
            "nullable": true,
            "type": {
             "keyType": "string",
             "type": "map",
             "valueContainsNull": true,
             "valueType": "string"
            }
           },
           {
            "metadata": {},
            "name": "userMetadata",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "engineInfo",
            "nullable": true,
            "type": "string"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 17
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"jobId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"runId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobOwnerId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"triggerType\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY employee_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8be5f8dc-aaa0-4dbe-9095-b76e88c06e07",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>9</td><td>2023-06-20T17:01:12.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>8</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>8</td><td>2023-06-20T17:01:10.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>7</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>7</td><td>2023-06-20T17:01:08.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>6</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>6</td><td>2023-06-20T17:00:42.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>5</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>5</td><td>2023-06-20T17:00:40.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>4</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>4</td><td>2023-06-20T17:00:37.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>3</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>3</td><td>2023-06-20T16:55:42.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>2</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>2</td><td>2023-06-20T16:55:40.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>1</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>1</td><td>2023-06-20T16:55:36.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, partitionBy -> [])</td><td>null</td><td>List(2207359188060060)</td><td>0619-182143-stpqxci1</td><td>0</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 1521)</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr><tr><td>0</td><td>2023-06-19T18:32:33.000+0000</td><td>677491494183077</td><td>chinthave@gmail.com</td><td>CREATE TABLE</td><td>Map(isManaged -> false, description -> null, partitionBy -> [], properties -> {\"description\":\"table created for demo purpose\"})</td><td>null</td><td>List(3644201334229790)</td><td>0619-182143-stpqxci1</td><td>null</td><td>WriteSerializable</td><td>true</td><td>Map()</td><td>null</td><td>Databricks-Runtime/13.0.x-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         9,
         "2023-06-20T17:01:12.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         8,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         8,
         "2023-06-20T17:01:10.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         7,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         7,
         "2023-06-20T17:01:08.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         6,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         6,
         "2023-06-20T17:00:42.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         5,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         5,
         "2023-06-20T17:00:40.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         4,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         4,
         "2023-06-20T17:00:37.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         3,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         3,
         "2023-06-20T16:55:42.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         2,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         2,
         "2023-06-20T16:55:40.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         1,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         1,
         "2023-06-20T16:55:36.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]"
         },
         null,
         [
          "2207359188060060"
         ],
         "0619-182143-stpqxci1",
         0,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "1521",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ],
        [
         0,
         "2023-06-19T18:32:33.000+0000",
         "677491494183077",
         "chinthave@gmail.com",
         "CREATE TABLE",
         {
          "description": null,
          "isManaged": "false",
          "partitionBy": "[]",
          "properties": "{\"description\":\"table created for demo purpose\"}"
         },
         null,
         [
          "3644201334229790"
         ],
         "0619-182143-stpqxci1",
         null,
         "WriteSerializable",
         true,
         {},
         null,
         "Databricks-Runtime/13.0.x-scala2.12"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"jobId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"runId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobOwnerId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"triggerType\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(deltaInstance2.history())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cfa7df1-475b-4e06-b365-753d00aca2ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2692002494841711,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Delta Table Instance",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
